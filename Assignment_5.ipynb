{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grade: /100 pts\n",
    "\n",
    "# Assignment 05: Model Selection & Cross Validation\n",
    "\n",
    "### You're a Data Scientist!\n",
    "You are working as a Junior Data Scientist for a professional football (er, Soccer) club.  The owner of the team is very interested in seeing how the use of data can help improve the team's peformance, and perhaps win them a championship!\n",
    "\n",
    "The draft is coming up soon (thats when you get to pick new players for your team), and the owner has asked you to create a model to help score potential draftees.  The model should look at attributes about the player and predict what their \"rating\" will be once they start playing professionally.\n",
    "\n",
    "The football club's data team has provided you with data for 17,993 footballers from the league.  Your job: work with the Senior Data Scientist to build a model or models, perform model selection, and make predictions on players you have not yet seen.\n",
    "\n",
    "### The Dataset\n",
    "\n",
    "The data is stored in a csv file called `footballer_data.csv`.  The data contain 52 columns, including some information about the player, their skills, and their overall measure as an effective footballer.\n",
    "\n",
    "Most features relate to the player's abilities in football related skills, such as passing, shooting, dribbling, etc.  Some features are rated on a 1-5 scale (5 being the best), others are rated on 0-100 (100 being the best), and others still are categorical (e.g. work rate is coded as low, medium, or high).\n",
    "\n",
    "The target variable (or $y$ variable, if you will) is `overall`.  This is an overall measure of the footballer's skill and is rated from 0 to 100.  The most amazingly skilled footballer would be rated 100, where as I would struggle to score more than a 20. The model(s) you build should use the other features to predict `overall`.\n",
    "\n",
    "\n",
    "### Follow These Steps before submitting\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline.\n",
    "\n",
    "\n",
    "### Preliminaries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from math import ceil\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: /10pts\n",
    "\n",
    "Read in the data and take a look at the dataframe.  There should be 52 columns. The outcome of interest is called `overall` which gives an overall measure of player performance. Not all of the other columns are particularly useful for modelling though (for instance, `ID` is just a unique identifier for the player.  This is essentially an arbitrary number and has no bearing on the player's rating).\n",
    "\n",
    "The Senior Data Scientist thinks the following columns should be removed:\n",
    "\n",
    "* ID\n",
    "* club\n",
    "* club_logo\n",
    "* birth_date\n",
    "* flag\n",
    "* nationality\n",
    "* photo\n",
    "* potential\n",
    "\n",
    "The Senior Data Scientist would also like the following columns converted into dummy variables:\n",
    "\n",
    "* work_rate_att\n",
    "* work_rate_def\n",
    "* preferred_foot\n",
    "\n",
    "Clean the data according to the Senior Data Scientist's instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>overall</th>\n",
       "      <th>pac</th>\n",
       "      <th>sho</th>\n",
       "      <th>pas</th>\n",
       "      <th>dri</th>\n",
       "      <th>def</th>\n",
       "      <th>phy</th>\n",
       "      <th>international_reputation</th>\n",
       "      <th>skill_moves</th>\n",
       "      <th>weak_foot</th>\n",
       "      <th>crossing</th>\n",
       "      <th>finishing</th>\n",
       "      <th>heading_accuracy</th>\n",
       "      <th>short_passing</th>\n",
       "      <th>volleys</th>\n",
       "      <th>dribbling</th>\n",
       "      <th>curve</th>\n",
       "      <th>free_kick_accuracy</th>\n",
       "      <th>long_passing</th>\n",
       "      <th>ball_control</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>sprint_speed</th>\n",
       "      <th>agility</th>\n",
       "      <th>reactions</th>\n",
       "      <th>balance</th>\n",
       "      <th>shot_power</th>\n",
       "      <th>jumping</th>\n",
       "      <th>stamina</th>\n",
       "      <th>strength</th>\n",
       "      <th>long_shots</th>\n",
       "      <th>aggression</th>\n",
       "      <th>interceptions</th>\n",
       "      <th>positioning</th>\n",
       "      <th>vision</th>\n",
       "      <th>penalties</th>\n",
       "      <th>composure</th>\n",
       "      <th>marking</th>\n",
       "      <th>standing_tackle</th>\n",
       "      <th>work_rate_att_Low</th>\n",
       "      <th>work_rate_att_Medium</th>\n",
       "      <th>work_rate_def_Low</th>\n",
       "      <th>work_rate_def_Medium</th>\n",
       "      <th>preferred_foot_Right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>185.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>96</td>\n",
       "      <td>63</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>92</td>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>95</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>170.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>97</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>92</td>\n",
       "      <td>87</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>68</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>88</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>93</td>\n",
       "      <td>90</td>\n",
       "      <td>78</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>175.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>96</td>\n",
       "      <td>81</td>\n",
       "      <td>84</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "      <td>96</td>\n",
       "      <td>88</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>56</td>\n",
       "      <td>36</td>\n",
       "      <td>90</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>182.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>90</td>\n",
       "      <td>79</td>\n",
       "      <td>87</td>\n",
       "      <td>42</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>64</td>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "      <td>87</td>\n",
       "      <td>69</td>\n",
       "      <td>89</td>\n",
       "      <td>80</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>41</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>193.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>89</td>\n",
       "      <td>60</td>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>48</td>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>78</td>\n",
       "      <td>44</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>70</td>\n",
       "      <td>47</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>17</td>\n",
       "      <td>188.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17990</th>\n",
       "      <td>47</td>\n",
       "      <td>185.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>46</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17991</th>\n",
       "      <td>17</td>\n",
       "      <td>175.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>77</td>\n",
       "      <td>42</td>\n",
       "      <td>73</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17992</th>\n",
       "      <td>18</td>\n",
       "      <td>176.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>25</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>74</td>\n",
       "      <td>43</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17993</th>\n",
       "      <td>18</td>\n",
       "      <td>182.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>48</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>17</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17994 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height_cm  weight_kg  overall  pac  sho  pas  dri  def  phy  \\\n",
       "0       32      185.0       80.0       94   90   93   82   90   33   80   \n",
       "1       30      170.0       72.0       93   89   90   86   96   26   61   \n",
       "2       25      175.0       68.0       92   92   84   79   95   30   60   \n",
       "3       30      182.0       86.0       92   82   90   79   87   42   81   \n",
       "4       31      193.0       92.0       92   91   90   95   89   60   91   \n",
       "...    ...        ...        ...      ...  ...  ...  ...  ...  ...  ...   \n",
       "17989   17      188.0       74.0       46   46   47   49   48   28   42   \n",
       "17990   47      185.0       77.0       46   39   50   39   37   25   50   \n",
       "17991   17      175.0       71.0       46   58   47   35   43   20   33   \n",
       "17992   18      176.0       61.0       46   58   35   44   45   45   47   \n",
       "17993   18      182.0       72.0       46   49   20   24   30   41   61   \n",
       "\n",
       "       international_reputation  skill_moves  weak_foot  crossing  finishing  \\\n",
       "0                             5            5          4        85         94   \n",
       "1                             5            4          4        77         95   \n",
       "2                             5            5          5        75         89   \n",
       "3                             5            4          4        77         94   \n",
       "4                             5            1          4        15         13   \n",
       "...                         ...          ...        ...       ...        ...   \n",
       "17989                         1            1          2        14          5   \n",
       "17990                         1            1          2        11         11   \n",
       "17991                         1            2          2        28         47   \n",
       "17992                         1            2          2        34         32   \n",
       "17993                         1            2          3        19         20   \n",
       "\n",
       "       heading_accuracy  short_passing  volleys  dribbling  curve  \\\n",
       "0                    88             83       88         91     81   \n",
       "1                    71             88       85         97     89   \n",
       "2                    62             81       83         96     81   \n",
       "3                    77             83       88         86     86   \n",
       "4                    25             55       11         30     14   \n",
       "...                 ...            ...      ...        ...    ...   \n",
       "17989                10             19        6         12     13   \n",
       "17990                12             12       12         11     12   \n",
       "17991                47             42       33         37     32   \n",
       "17992                40             49       25         41     30   \n",
       "17993                48             31       19         23     17   \n",
       "\n",
       "       free_kick_accuracy  long_passing  ball_control  acceleration  \\\n",
       "0                      76            77            93            89   \n",
       "1                      90            87            95            92   \n",
       "2                      84            75            95            94   \n",
       "3                      84            64            91            88   \n",
       "4                      11            59            48            58   \n",
       "...                   ...           ...           ...           ...   \n",
       "17989                  12            21            12            24   \n",
       "17990                  11            13            22            25   \n",
       "17991                  25            30            41            66   \n",
       "17992                  34            44            43            57   \n",
       "17993                  17            24            32            48   \n",
       "\n",
       "       sprint_speed  agility  reactions  balance  shot_power  jumping  \\\n",
       "0                91       89         96       63          94       95   \n",
       "1                87       90         95       95          85       68   \n",
       "2                90       96         88       82          80       61   \n",
       "3                77       86         93       60          87       69   \n",
       "4                61       52         85       35          25       78   \n",
       "...             ...      ...        ...      ...         ...      ...   \n",
       "17989            32       38         40       26          19       31   \n",
       "17990            25       35         51       44          13       51   \n",
       "17991            51       60         54       77          42       73   \n",
       "17992            58       58         49       74          43       56   \n",
       "17993            49       49         40       47          21       60   \n",
       "\n",
       "       stamina  strength  long_shots  aggression  interceptions  positioning  \\\n",
       "0           92        80          92          63             29           95   \n",
       "1           73        59          88          48             22           93   \n",
       "2           78        53          77          56             36           90   \n",
       "3           89        80          86          78             41           92   \n",
       "4           44        83          16          29             30           12   \n",
       "...        ...       ...         ...         ...            ...          ...   \n",
       "17989       28        50           7          16              9            6   \n",
       "17990       32        47          16          44             16           13   \n",
       "17991       33        32          51          26             16           46   \n",
       "17992       49        46          32          46             46           37   \n",
       "17993       55        67          17          52             38           20   \n",
       "\n",
       "       vision  penalties  composure  marking  standing_tackle  \\\n",
       "0          85         85         95       22               31   \n",
       "1          90         78         96       13               28   \n",
       "2          80         81         92       21               24   \n",
       "3          84         85         83       30               45   \n",
       "4          70         47         70       10               10   \n",
       "...       ...        ...        ...      ...              ...   \n",
       "17989      26         17         23        9               11   \n",
       "17990      17         22         44       14               12   \n",
       "17991      37         58         50       18               17   \n",
       "17992      51         43         45       43               48   \n",
       "17993      22         21         33       38               44   \n",
       "\n",
       "       work_rate_att_Low  work_rate_att_Medium  work_rate_def_Low  \\\n",
       "0                      0                     0                  1   \n",
       "1                      0                     1                  0   \n",
       "2                      0                     0                  0   \n",
       "3                      0                     0                  0   \n",
       "4                      0                     1                  0   \n",
       "...                  ...                   ...                ...   \n",
       "17989                  0                     1                  0   \n",
       "17990                  0                     1                  0   \n",
       "17991                  0                     1                  0   \n",
       "17992                  0                     1                  0   \n",
       "17993                  0                     1                  0   \n",
       "\n",
       "       work_rate_def_Medium  preferred_foot_Right  \n",
       "0                         0                     1  \n",
       "1                         1                     0  \n",
       "2                         1                     1  \n",
       "3                         1                     1  \n",
       "4                         1                     1  \n",
       "...                     ...                   ...  \n",
       "17989                     1                     1  \n",
       "17990                     1                     1  \n",
       "17991                     1                     0  \n",
       "17992                     1                     1  \n",
       "17993                     1                     0  \n",
       "\n",
       "[17994 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data.\n",
    "model_data = pd.read_csv(\"footballer_data.csv\")\n",
    "\n",
    "# Dropping unnecessary columns, getting dummy variables.\n",
    "model_data = model_data.drop(columns = [\"ID\", \"club\", \"club_logo\", \"birth_date\", \"flag\", \"nationality\", \"photo\", \"potential\"])\n",
    "model_data = pd.get_dummies(model_data, drop_first=True)\n",
    "\n",
    "# Displaying cleaned data.\n",
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: /10 pts\n",
    "\n",
    "The data should all be numerical now. To evalute different models, define a function that returns the mean absolute error. Before we begin modelling, it is important to obtain a baseline for the accuracy of our predictive models. Compute the absolute errors resulting if we use the median of the `overall` variable to make predictions. This will serve as our baseline performance. Plot the distribution of the errors and print their mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 5.491330443481161, stdev: 4.261886186448831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa14b98bb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define mean absolute error function  \n",
    "def absolute_error(y_hat, y):\n",
    "    return abs(y_hat-y)\n",
    "\n",
    "def mean_absolute_error(y_hat, y):\n",
    "    return np.mean(abs(y_hat-y))\n",
    "    \n",
    "# Retrieving y data.\n",
    "y= model_data.overall\n",
    "\n",
    "# Creating prediction array of just the median for the baseline.\n",
    "median = np.median(model_data.overall)\n",
    "y_hat = np.repeat(median, len(y))\n",
    "\n",
    "# Getting MAE, and standard deviation of the errors.\n",
    "errors = absolute_error(y_hat, y)\n",
    "mae = mean_absolute_error(y_hat, y)\n",
    "stdev = np.std(errors)\n",
    "\n",
    "# Printing mean and standard deviation of errors.\n",
    "print(\"Mean: {}, stdev: {}\".format(mae, stdev))\n",
    "\n",
    "\n",
    "# Plot distribution  \n",
    "sns.displot(errors).set(xlabel=\"Absolute Error\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: /15pts\n",
    "To prepare the data for modelling, the Senior Data Scientist recomends you use `sklearn.model_selection.train_test_split` to seperate the data into a training set and a test set.\n",
    "\n",
    "The Senior Data Scientist would like to estimate the performance of the final selected model to within +/- 0.25 units using mean absolute error as the loss function of choice.  \n",
    "\n",
    "Using the formula for the effective test size ($n$) to get the precision to specific precision ($d$) relative to the test loss standard deviation of $\\sigma_l$\n",
    "$$ n = \\left(\\frac{1.96 \\sigma_l}{d}\\right)^2$$,\n",
    "\n",
    "decide on an appropriate size for the test set, then use `train_test_split` to split the features and target variables into appropriate sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1117\n",
      "(16877, 45) (1117, 45)\n"
     ]
    }
   ],
   "source": [
    "# Define X and y.\n",
    "y = model_data.overall\n",
    "X = model_data.drop(columns=[\"overall\"])\n",
    "\n",
    "# Get effective test size.\n",
    "precision = 0.25\n",
    "n = ceil((1.96 * stdev / precision) ** 2) \n",
    "print(n)\n",
    "\n",
    "# Split into train and test data.\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size = n, random_state = 0)\n",
    "print(Xtrain.shape,Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: /5pts\n",
    "The Senior Data Scientist wants you to fit a linear regression to the data as a first model.  Use sklearn to build a model pipeline which fits a linear regression to the data. You can read up on sklearn pipelines [here](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). Note that the sklearn linear regression adds its own intercept so you don't need to create a column of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple model pipeline for linear regression. Fitting it.\n",
    "model = Pipeline([('linear', LinearRegression())])\n",
    "model = model.fit(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: /15pts\n",
    "\n",
    "The senior data scientist wants a report of this model's cross validation score.  Use 5 fold cross validation to estimate the out of sample performance for this model, using your mean absolute error function from question 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.9002586833510358\n",
      "CV loss: 1.9059891546471561\n"
     ]
    }
   ],
   "source": [
    "# Printing the training loss \n",
    "print(\"Training loss:{}\".format(mean_absolute_error(ytrain, model.predict(Xtrain))))\n",
    "\n",
    "# Getting KFolds. Not shuffling because the train_test_split already shuffled.\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Creating scorer and getting the cross-validation score. Printing it.\n",
    "sc = make_scorer(mean_absolute_error)\n",
    "cv_score = cross_val_score(model,Xtrain,ytrain,cv=kf, scoring=sc)\n",
    "print(\"CV loss: {}\".format(cv_score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: /15pts\n",
    "\n",
    "That's impressive!  Your model seems to be very accurate, but now the Senior Data Scientist wants to try and make it more accurate.  Scouts have shared with the Senior Data Scientist that players hit their prime in their late 20s, and as they age they become worse overall.\n",
    "\n",
    "The Senior Data Scientist wants to add a quadratic term for age to the model.  Repeat the steps above (creating a pipeline, validating the model, etc) for a model which includes a quadratic term for age. As in the Lab, include the addition of the quadratic term for Age as a Transform into the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:1.8816836456303476\n",
      "CV loss: 1.887456645428739\n"
     ]
    }
   ],
   "source": [
    "# Creating a class for the custom transformer.\n",
    "class Age2(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = X.assign(age2 = X.age**2)\n",
    "        return X\n",
    "\n",
    "# Creating a pipeline with this \n",
    "model2 = Pipeline(steps=[('age2', Age2()), ('linear_regression', LinearRegression())])\n",
    "model2 = model2.fit(Xtrain, ytrain)\n",
    "\n",
    "# Printing training and CV loss.\n",
    "print(\"Training loss:{}\".format(mean_absolute_error(ytrain, model2.predict(Xtrain))))\n",
    "\n",
    "cv_score2 = cross_val_score(model2, Xtrain, ytrain, cv=kf, scoring = sc)\n",
    "print(\"CV loss: {}\".format(cv_score2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: /10 pts\n",
    "\n",
    "\n",
    "The Senior Data Scientist isn't too happy that the quadratic term has not improved the fit of the model much and now wants to include quadratic and interaction term for every feature (That's a total of 1080 features!!!!)\n",
    "\n",
    "Add sklearn's `PolynomialFeatures` to your pipeline.  Report the cross validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.8200582960735946\n",
      "CV loss: 0.8849889217353223\n"
     ]
    }
   ],
   "source": [
    "# Getting polynomial transform item.\n",
    "PT = PolynomialFeatures(degree = 2, include_bias=False)\n",
    "\n",
    "# Creating pipeline and fitting it.\n",
    "model3 = Pipeline([('poly', PT), ('linear_regression', LinearRegression())])\n",
    "model3 = model3.fit(Xtrain, ytrain)\n",
    "\n",
    "# Printing training and CV loss.\n",
    "print(\"Training loss:{}\".format(mean_absolute_error(ytrain,model3.predict(Xtrain))))\n",
    "\n",
    "cv_score3 = cross_val_score(model3, Xtrain, ytrain, cv=kf, scoring = sc)\n",
    "print(\"CV loss: {}\".format(cv_score3.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: /10pts\n",
    "\n",
    "The Senior Data Scientist is really happy with the results of adding every interaction into the model and wants to explore third order interactions (that is adding cubic terms to the model).\n",
    "\n",
    "This is not a good idea!  Talk them down from the ledge.  Write them an email in the cell below explaining what could happen if you add too may interactions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey Boss,\n",
    "\n",
    "Adding third order interactions is not a great idea. First of all, it would be very, *very* computationally complex with an order of magnitude more features, and take a long time to load. Moreover, with so many features we risk overfitting and high variance, which would be bad for data outside of our training set, and lead to worse error. It's important we stick with quadratic, a good medium of specificity and complexity, while also being generalizable enough for out-of-sample data.\n",
    "\n",
    "Sincerly,\n",
    "\n",
    "Junior Data Scientist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9:  /10pts\n",
    "\n",
    "You've successfully talked the Senior Data Scientist out of adding cubic terms to the model. Good job!\n",
    "\n",
    "Based on the cross validation scores, which model would you choose?  \n",
    "Train you model on all the training data. \n",
    "Estimate the performance of your chosen model on the test data you held out, and do the following:\n",
    "\n",
    "- Compute a point estimate for the generalization error.\n",
    "- Compute a confidence interval for the generalization error.  \n",
    "- Plot the distribution of the absolute errors.\n",
    "\n",
    "Is the test error close to the cross validation error of the model you chose? Why do you think this is the case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point estimate: 0.8751650745361668, confidence interval:(0.8281335090063686,0.9221966400659649)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Written answer: this is close to the cross validation error of the model I chose, but slightly less. This is because test error tends to underestimate the actual error. The values are close, however, because an independent validation/training set was used and both the validation and test sets were randomly selected samples from the data.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using model 3 because it had the lowest cross-validation error. Model 3 has already been trained on all the training data.\n",
    "\n",
    "y_hat = model3.predict(Xtest)\n",
    "errors = absolute_error(y_hat, ytest)\n",
    "mae = mean_absolute_error(y_hat, ytest)\n",
    "sns.displot(errors).set(xlabel=\"Absolute Errors\")\n",
    "interval_precision = 1.96*np.std(errors)/np.sqrt(len(errors))\n",
    "print(\"Point estimate: {}, confidence interval:({},{})\".format(mae, mae-interval_precision, mae+interval_precision))\n",
    "\n",
    "\n",
    "'''Written answer: this is close to the cross validation error of the model I chose, but slightly less. This is because test error tends to underestimate the actual error. The values are close, however, because an independent validation/training set was used and both the validation and test sets were randomly selected samples from the data.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Follow These Steps before submitting\n",
    "Once you are finished, ensure to complete the following steps.\n",
    "\n",
    "1.  Restart your kernel by clicking 'Kernel' > 'Restart & Run All'.\n",
    "\n",
    "2.  Fix any errors which result from this.\n",
    "\n",
    "3.  Repeat steps 1. and 2. until your notebook runs without errors.\n",
    "\n",
    "4.  Submit your completed notebook to OWL by the deadline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
